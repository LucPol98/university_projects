{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import gym\n",
    "import Pacman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the game is set: \n",
    "\n",
    "Pacman's goal is to eat all the balls in the grid without dying. At the end of each episode is reported the total reward that has been accumulated and the max_reward that is computed based on how many balls are on the map. If Pacman hits a ghost, it dies losing an high number of points and returns to the starting position without resetting the map, so the balls already eaten will not be restored. In the original game this happens a maximum of 3 three times, after which you die permanently and the map is reset. In this simplified version there is no limit to the times pacman can return to the starting position when it dies without resetting the map.\n",
    "\n",
    "The size of the grid is not editable and it is 8x8 in size. You can define step_cost, ghosts, and obstacles. The environment is fully observable. Ghosts and walls are static. Pacman performs random actions. As shown in the guide on the gym website, it is possible to play \"max_episodes\" times each of which is made up of \"max_iter_for_ep\" iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "max_episodes=1\n",
    "max_iter_for_ep=10\n",
    "# the step_cost is the reward of each ball and it is multipled for the negative reward when Pacman hits a ghosts\n",
    "step_cost = 1\n",
    "# It is not necessary to set perimeter obstacles because they will be set by default\n",
    "ostacoli =[(2, 3),\n",
    "           (3, 2), (3, 3),\n",
    "           (4, 2), \n",
    "           (5, 4), (5, 5)]\n",
    "fantasmi = [(1, 5),\n",
    "            (3, 1), (3, 6),\n",
    "            (4, 5), \n",
    "            (6, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The environment grid is 8x8 in size and it is composed as follows:\n",
      "\n",
      "[['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']\n",
      " ['Wal' 'Pac' '0.0' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Wal' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Gho' 'Wal' 'Wal' '0.0' '0.0' 'Gho' 'Wal']\n",
      " ['Wal' '0.0' 'Wal' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' 'Wal' 'Wal' '0.0' 'Wal']\n",
      " ['Wal' '0.0' 'Gho' '0.0' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']]\n",
      "\n",
      "Next selected action: down\n",
      "Reward obtained from this action: 1.0\n",
      "\n",
      "[['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' 'Pac' '0.0' 'Wal' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Gho' 'Wal' 'Wal' '0.0' '0.0' 'Gho' 'Wal']\n",
      " ['Wal' '0.0' 'Wal' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' 'Wal' 'Wal' '0.0' 'Wal']\n",
      " ['Wal' '0.0' 'Gho' '0.0' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']]\n",
      "\n",
      "Next selected action: down\n",
      "Reward obtained from this action: -10.0\n",
      "You have been eaten! Start over without resecting the map\n",
      "\n",
      "[['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']\n",
      " ['Wal' 'Pac' '0.0' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Wal' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Gho' 'Wal' 'Wal' '0.0' '0.0' 'Gho' 'Wal']\n",
      " ['Wal' '0.0' 'Wal' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' 'Wal' 'Wal' '0.0' 'Wal']\n",
      " ['Wal' '0.0' 'Gho' '0.0' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']]\n",
      "\n",
      "Next selected action: right\n",
      "Reward obtained from this action: 1.0\n",
      "\n",
      "[['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']\n",
      " ['Wal' '0.0' 'Pac' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Wal' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Gho' 'Wal' 'Wal' '0.0' '0.0' 'Gho' 'Wal']\n",
      " ['Wal' '0.0' 'Wal' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' 'Wal' 'Wal' '0.0' 'Wal']\n",
      " ['Wal' '0.0' 'Gho' '0.0' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']]\n",
      "\n",
      "Next selected action: right\n",
      "Reward obtained from this action: 1.0\n",
      "\n",
      "[['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Pac' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Wal' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Gho' 'Wal' 'Wal' '0.0' '0.0' 'Gho' 'Wal']\n",
      " ['Wal' '0.0' 'Wal' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' 'Wal' 'Wal' '0.0' 'Wal']\n",
      " ['Wal' '0.0' 'Gho' '0.0' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']]\n",
      "\n",
      "Next selected action: down\n",
      "Reward obtained from this action: 0.0\n",
      "\n",
      "[['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Pac' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Wal' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Gho' 'Wal' 'Wal' '0.0' '0.0' 'Gho' 'Wal']\n",
      " ['Wal' '0.0' 'Wal' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' 'Wal' 'Wal' '0.0' 'Wal']\n",
      " ['Wal' '0.0' 'Gho' '0.0' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']]\n",
      "\n",
      "Next selected action: down\n",
      "Reward obtained from this action: 0.0\n",
      "\n",
      "[['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Pac' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Wal' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Gho' 'Wal' 'Wal' '0.0' '0.0' 'Gho' 'Wal']\n",
      " ['Wal' '0.0' 'Wal' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' 'Wal' 'Wal' '0.0' 'Wal']\n",
      " ['Wal' '0.0' 'Gho' '0.0' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']]\n",
      "\n",
      "Next selected action: left\n",
      "Reward obtained from this action: 0.0\n",
      "\n",
      "[['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']\n",
      " ['Wal' '0.0' 'Pac' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Wal' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Gho' 'Wal' 'Wal' '0.0' '0.0' 'Gho' 'Wal']\n",
      " ['Wal' '0.0' 'Wal' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' 'Wal' 'Wal' '0.0' 'Wal']\n",
      " ['Wal' '0.0' 'Gho' '0.0' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']]\n",
      "\n",
      "Next selected action: right\n",
      "Reward obtained from this action: 0.0\n",
      "\n",
      "[['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Pac' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Wal' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Gho' 'Wal' 'Wal' '0.0' '0.0' 'Gho' 'Wal']\n",
      " ['Wal' '0.0' 'Wal' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' 'Wal' 'Wal' '0.0' 'Wal']\n",
      " ['Wal' '0.0' 'Gho' '0.0' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']]\n",
      "\n",
      "Next selected action: right\n",
      "Reward obtained from this action: 1.0\n",
      "\n",
      "[['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' 'Pac' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Wal' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Gho' 'Wal' 'Wal' '0.0' '0.0' 'Gho' 'Wal']\n",
      " ['Wal' '0.0' 'Wal' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' 'Wal' 'Wal' '0.0' 'Wal']\n",
      " ['Wal' '0.0' 'Gho' '0.0' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']]\n",
      "\n",
      "Next selected action: down\n",
      "Reward obtained from this action: 1.0\n",
      "\n",
      "[['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' 'Wal' 'Pac' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Gho' 'Wal' 'Wal' '0.0' '0.0' 'Gho' 'Wal']\n",
      " ['Wal' '0.0' 'Wal' '0.0' '0.0' 'Gho' '0.0' 'Wal']\n",
      " ['Wal' '0.0' '0.0' '0.0' 'Wal' 'Wal' '0.0' 'Wal']\n",
      " ['Wal' '0.0' 'Gho' '0.0' '0.0' '0.0' '0.0' 'Wal']\n",
      " ['Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal' 'Wal']]\n",
      "\n",
      "Episode Completed\n",
      "The final reward of the episode number 1 is -5.0 out of a maximum of 24.0\n",
      "\n",
      "####################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_env = gym.make('PacManGame-v0', step_cost=step_cost, ghosts=fantasmi, obstacles=ostacoli)\n",
    "\n",
    "for i in range(max_episodes):\n",
    "    my_env.reset()\n",
    "    print(my_env.descrEnv())\n",
    "    my_env.render()\n",
    "    for j in range(max_iter_for_ep):\n",
    "        obs, reward, done, info = my_env.step(my_env.action_space.sample()) # take a random action\n",
    "        print(info)\n",
    "        my_env.render()\n",
    "        if(done):\n",
    "            print(\"\\nYou ate all the balls. You won!!\")\n",
    "            break;\n",
    "    datiRew = my_env.ritValReward()\n",
    "    print(\"\\nEpisode Completed\\nThe final reward of the episode number \"+str(i+1)+\" is \"+str(datiRew[0])+\" out of a maximum of \"+str(datiRew[1]))\n",
    "    print(\"\\n####################################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
